services:
  postgres_db:
    build: ./postgres
    container_name: postgres_db
    env_file: .env
    environment:
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    ports:
      - "${POSTGRES_PORT}:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - etl-network

  data_generator:
    build: ./data_generator

  airflow:
    build: ./airflow
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres_db:5432/${POSTGRES_DB}
      AIRFLOW__CORE__LOAD_EXAMPLES: "false"
      AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: "true"
      AIRFLOW__CORE__SIMPLE_AUTH_MANAGER_ALL_ADMINS: "true"
      AIRFLOW_VAR_POSTGRES_DB: ${POSTGRES_DB}
      AIRFLOW_VAR_POSTGRES_USER: ${POSTGRES_USER}
      AIRFLOW_VAR_POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      AIRFLOW_VAR_POSTGRES_PORT: ${POSTGRES_PORT}
      AIRFLOW_VAR_POSTGRES_HOST: postgres_db
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - /var/run/docker.sock:/var/run/docker.sock
    ports:
      - "${AIRFLOW_PORT}:8080"
    command: airflow standalone
    depends_on:
      - postgres_db
    networks:
      - etl-network

  spark:
    image: apache/spark:3.5.0
    build: ./spark
    container_name: spark
    env_file: .env
    environment:
      - SPARK_MODE=master
    volumes:
      - ./spark/scripts:/opt/spark/scripts
    command: ["/opt/spark/bin/spark-class", "org.apache.spark.deploy.master.Master"]
    ports:
      - "${SPARK_UI_PORT}:8080"  # Spark UI
      - "${SPARK_MASTER_PORT}:7077"  # Spark master
    networks:
      - etl-network

  spark-worker:
    image: apache/spark:3.5.0
    build: ./spark
    container_name: spark-worker
    env_file: .env
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark:7077
    command: ["/opt/spark/bin/spark-class", "org.apache.spark.deploy.worker.Worker", "spark://spark:7077"]
    depends_on:
      - spark
    networks:
      - etl-network

volumes:
  postgres_data:

networks:
  etl-network:
    name: user-segments-etl-pipeline_etl-network
    driver: bridge